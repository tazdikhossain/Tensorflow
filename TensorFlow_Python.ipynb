{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#TensorFlow\n",
        "TensorFlow-> Powerful Deep Learning library for python.(Open Source)\n",
        "Google AI team-(Google AI)\n",
        "\n",
        "TensorFlow-> An end-to-end open source framework for deep learning that works with python.\n",
        "\n",
        "Tensors-> Multi-dimensional data arrays\n",
        "Flow-> Numerical computations via graphs(data Flow)\n",
        "\n",
        "A flow of tensors which is fundamental to the working of a neural network."
      ],
      "metadata": {
        "id": "WjE7U29joPoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors\n",
        "1. Linear Algebra\n",
        "2. vector calculas\n",
        "3. Python syntax\n",
        "\n",
        "Tensors are object that describes a relationship between algebric objects and vector spaces associated to them.\n",
        "\n",
        "For Tensors we need n^r where r is the rank of a tensor.\n",
        "\n"
      ],
      "metadata": {
        "id": "p8U7bSUQquDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Networks\n",
        "1. NN is a pathway to Artificial intelligence using Deep Learning\n",
        "\n",
        "2. Artificial Neural Networks (ANNs) are inspired from the neurons present in the neurons present in the human body.\n",
        "\n",
        "3. Neural avtivations is based on circumstances which in turn allows for response and actions\n",
        "\n",
        "Each neurons receives multiplied version of inputs and random weights which is added with the bias value.\n",
        "Later, this is passed through an activation function that gives the neurons its final value.\n",
        "\n",
        "Weights->\n",
        "1. weights are values that get multiplied with the inputs for the neurons\n",
        "2. They are used later during backpropagation to reduce the loss.\n",
        "3. Weights are adjustable depending on the training input and the prediction outcome variation."
      ],
      "metadata": {
        "id": "oT8WkYZCwTYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorFlow code writing process\n",
        "\n",
        "1. Creating the computational grapg from tensors\n",
        "2. Running the graph to denote graph operations"
      ],
      "metadata": {
        "id": "Efx5_TSd0jfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the computational grapg from tensors\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "x=tf.constant(10.0)\n",
        "y=tf.constant(15.0)\n",
        "z=x+y\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bQXygBY0OzT",
        "outputId": "91d92a6a-439a-4aa6-d2b2-401e3d7a2d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(25.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Character Recognition with TensorFlow\n",
        "1. Digit classification using the MNIST dataset\n"
      ],
      "metadata": {
        "id": "u8dra4yh3bnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Load TensorFlow\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#2. load MNIST dataset and convert sames to floating point numbers from integers\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "\n",
        "#3. Build the model, choose an optimizer and the loss function\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10)])\n",
        "\n",
        "#4. Take a look at what the model is doing in terms of outputs - vectors:\n",
        "predictions = model(x_train[:1]).numpy()\n",
        "predictions\n",
        "\n",
        "#5. We need the probability of each class instead of the vectors\n",
        "tf.nn.softmax(predictions).numpy() #softmax->\n",
        "\n",
        "#6. Finding the scalar loss for each example:\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "loss_fn(y_train[:1], predictions).numpy()\n",
        "\n",
        "#7. Model Compilation\n",
        "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
        "\n",
        "#8. Model fitting to the minimize the loss\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "#9. Model Evaluation\n",
        "model.evaluate(x_test, y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D99rAkMs3iN8",
        "outputId": "377af230-5bbf-4b91-9bed-f0fe66d66088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2965 - accuracy: 0.9140\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1418 - accuracy: 0.9585\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1048 - accuracy: 0.9682\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0864 - accuracy: 0.9736\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0741 - accuracy: 0.9775\n",
            "313/313 - 1s - loss: 0.0782 - accuracy: 0.9761 - 934ms/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07817672938108444, 0.9761000275611877]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only doing epoch will not work as it will bring the concept overfitting and underfitting."
      ],
      "metadata": {
        "id": "5vYxAomm-16I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Image classification using CNNs\n",
        "1. Convolution layer - Converts image into an array\n",
        "--- first layer of a convolutional neral network\n",
        "--- stores the pixel values of image into an array\n",
        "--- used for extracting the features of the image and reducing its dimention.\n",
        "2. ReLu layer - Regularization used to vonvert negative numbers to zero\n",
        "--- regularization used to convert negative numbers to zero\n",
        "3. pooling Layer - Used for reduction of the input image size with filters\n",
        "--- used to reduce the spatial size and the number of parameters\n",
        "--- to reduce dimentionality\n",
        "--- helps to control overfitting\n",
        "--- filters of the size 2*2 are commonly used in it\n",
        "4. Fully connected layer- Combines features and produces a model.\n",
        "--- Combines all the features togather to create a final model\n",
        "--- final step in the process of a Convolutional Neural Network."
      ],
      "metadata": {
        "id": "WAZ5clmpAEiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. import training and testing dataset\n",
        "!wget https://www.dropbox.com/s/t4pzwpvrzneb190/training_set.zip\n",
        "!wget https://www.dropbox.com/s/i37jfni3d29raoc/test_set.zip\n",
        "\n",
        "#2. Unzipping the compressed dataset\n",
        "!unzip training_set.zip\n",
        "!unzip test_set.zip"
      ],
      "metadata": {
        "id": "P20xddgSIqmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Printing a sample image of a cat\n",
        "%pylab inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as npimg\n",
        "img = npimg.imread('/content/training_set/training_set/cats/cat.10.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s11krokx_g-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing a sample image of a dog\n",
        "img = npimg.imread('/content/training_set/training_set/dogs/dog.100.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WnXu8qT-IzGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " #4. Import Libraries\n",
        "import tensorflow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Activation\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg"
      ],
      "metadata": {
        "id": "Ps2BzC9kJLdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Parameter initialization\n",
        "# Initialize the paramaters\n",
        "\n",
        "image_width, image_height = 150,150\n",
        "train_data_dir = r\"/content/training_set\"\n",
        "validation_data_dir = r\"/content/test_set\"\n",
        "nb_train_sample = 100\n",
        "nb_validation_sample = 100\n",
        "epochs = 20 # repeating a proper cycle\n",
        "batch_size = 20 # model will not learn from the whole dataset\n"
      ],
      "metadata": {
        "id": "OBoJFu5zKJde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the shapes of the images\n",
        "# Images data is represented by a #D array:[rows][cols][channels]in a channel last representation. Channels are the first dimmention in channel first representation\n",
        "# 150*150*3\n",
        "\n",
        "import tensorflow.keras.backend as k\n",
        "if k.image_data_format()=='channels_first':\n",
        "  input_shape = (3, image_width, image_height)\n",
        "else:\n",
        "  input_shape = (image_width, image_height, 3)"
      ],
      "metadata": {
        "id": "kmRc56SuK_b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate image to train the model\n",
        "train_datagen = ImageDataGenerator(rescale=1. /255, shear_range = 0.2, zoom_range=0.2, horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_genarator = train_datagen.flow_from_directory(train_data_dir, target_size = (image_width, img_height), batch_size=batch_size, class_mode = 'binary', classes=['cat', 'dogs'])\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size = (image_width, img_height), batch_size = batch_size, class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMaqFVSlMa2m",
        "outputId": "66d1e5f7-6c57-4b03-9049-3be5b0ca5951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 2 classes.\n",
            "Found 2023 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visual representation of ImageDataGenerator\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "for i in range(0,15):\n",
        "  plt.subplot(5,3,i+1)\n",
        "  for X_batch, Y_batch in train_genarator:\n",
        "    image = X_batch[0]\n",
        "    plt.inshow(image)\n",
        "    break\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "I6seyLDANY2d",
        "outputId": "98715205-d20d-47a2-c19a-d1645a3f9813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-1884546c01c2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_genarator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the basic CNN model 0\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64,(3,3), input_shape = input_shape)) #64 neurons with 3*3 filter\n",
        "#This class allows to create convolutional neural network to extract features from the images\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(Maxpooling2D(pool_size=(2,2))) # MaxPooling2D helps to reduce the size of the data\n",
        "\n",
        "model.add(Flatten())# Converts multi dimentional array to 10 channel\n",
        "model.add(Dense(64))#64 neurons with 3*3 filter\n",
        "# numbers of output nodes in the hidden layers\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(1)) #Output layer\n",
        "model.add(Activation('sigmoid'))#sigmoid activation function\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "VaGx1PaDONKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the basic CNN model\n",
        "model.compile(optimizer = 'rnsprop', loss = 'binary_crossentropy', matrics = ['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "#Fit the basic CNN model\n",
        "training = model.fit_generator(train-generator, steps_per_epoch-nb_train_sample, epoch-epochs, validation_data-validaton_generator, validation-steps-nb_validaton_samples)\n"
      ],
      "metadata": {
        "id": "Nz4-rEncOSb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Find the accuracy score\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# list all data in training\n",
        "print(training.history.key())\n",
        "\n",
        "#summarize training for accuracy\n",
        "plt.plot(training.history['accuracy'])\n",
        "plt.plot(training.history['val_acccuracy'])\n",
        "plt.title('model accuracy')\n",
        "\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test']), loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "#summarize training for loss\n",
        "plt.plot(training.history['loss'])\n",
        "plt.plot(training.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test']), loc = 'upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xzniVmDYOZjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict the image\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "img_pred = image.load_img(\"\", target_size=(150,150))\n",
        "\n",
        "img_pred = image.img_to_array(img_pred)\n",
        "img_pred = np.expand_dims(img-pred, axis=0)\n",
        "\n",
        "rslt = model.predict(img_pred)\n",
        "print(rslt)\n",
        "if rslt [0][0]==1:\n",
        "  prediction = 'Dog'\n",
        "else:\n",
        "  prediction = 'cat'\n",
        "  print('predict:', prediction)\n",
        "\n",
        "  img-mpimg.imread('')\n",
        "  implot = plt.imshow(img)\n",
        "  plt.show"
      ],
      "metadata": {
        "id": "ZmAMJDIiOqGO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}